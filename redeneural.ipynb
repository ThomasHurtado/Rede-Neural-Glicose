{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3782b837",
   "metadata": {},
   "source": [
    "## Iniciando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "6dd4f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4802061",
   "metadata": {},
   "source": [
    "## Definindo o database, realizando limpeza de dados e definindo classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "febd7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('db.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "391c4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "6d31a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Glucose-type'] = 0\n",
    "df.loc[(df['Blood Glucose Level(BGL)'] > 80), 'Glucose-type'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "57490e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Diabetic/NonDiabetic (D/N)'] == 'N', 'Diabetic/NonDiabetic (D/N)'] = 1\n",
    "df.loc[df['Diabetic/NonDiabetic (D/N)'] == 'D', 'Diabetic/NonDiabetic (D/N)'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "4a1451f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Blood Glucose Level(BGL)</th>\n",
       "      <th>Diastolic Blood Pressure</th>\n",
       "      <th>Systolic Blood Pressure</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Body Temperature</th>\n",
       "      <th>SPO2</th>\n",
       "      <th>Sweating  (Y/N)</th>\n",
       "      <th>Shivering (Y/N)</th>\n",
       "      <th>Diabetic/NonDiabetic (D/N)</th>\n",
       "      <th>Glucose-type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>73</td>\n",
       "      <td>118</td>\n",
       "      <td>98</td>\n",
       "      <td>98.300707</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>119</td>\n",
       "      <td>102</td>\n",
       "      <td>98.300707</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>110</td>\n",
       "      <td>81</td>\n",
       "      <td>98.300707</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>115</td>\n",
       "      <td>96</td>\n",
       "      <td>98.300707</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>144</td>\n",
       "      <td>92</td>\n",
       "      <td>97.807052</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>127</td>\n",
       "      <td>90</td>\n",
       "      <td>96.842657</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16965</th>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>117</td>\n",
       "      <td>80</td>\n",
       "      <td>97.869454</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16966</th>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>116</td>\n",
       "      <td>93</td>\n",
       "      <td>96.766282</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16967</th>\n",
       "      <td>9</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>128</td>\n",
       "      <td>91</td>\n",
       "      <td>98.941036</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16968</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "      <td>117</td>\n",
       "      <td>79</td>\n",
       "      <td>97.570685</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16700 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Blood Glucose Level(BGL)  Diastolic Blood Pressure  \\\n",
       "0        9                        79                        73   \n",
       "1        9                        80                        73   \n",
       "2        9                        70                        76   \n",
       "3        9                        70                        78   \n",
       "4       66                       100                        96   \n",
       "...    ...                       ...                       ...   \n",
       "16964    9                        86                        87   \n",
       "16965    9                        84                        79   \n",
       "16966    9                        81                        82   \n",
       "16967    9                        82                        86   \n",
       "16968    9                        76                        85   \n",
       "\n",
       "       Systolic Blood Pressure  Heart Rate  Body Temperature  SPO2  \\\n",
       "0                          118          98         98.300707    99   \n",
       "1                          119         102         98.300707    94   \n",
       "2                          110          81         98.300707    98   \n",
       "3                          115          96         98.300707    96   \n",
       "4                          144          92         97.807052    98   \n",
       "...                        ...         ...               ...   ...   \n",
       "16964                      127          90         96.842657    97   \n",
       "16965                      117          80         97.869454    98   \n",
       "16966                      116          93         96.766282    98   \n",
       "16967                      128          91         98.941036    98   \n",
       "16968                      117          79         97.570685    97   \n",
       "\n",
       "       Sweating  (Y/N)  Shivering (Y/N) Diabetic/NonDiabetic (D/N)  \\\n",
       "0                    0                0                          1   \n",
       "1                    1                0                          1   \n",
       "2                    1                0                          1   \n",
       "3                    1                0                          1   \n",
       "4                    0                0                          1   \n",
       "...                ...              ...                        ...   \n",
       "16964                0                0                          0   \n",
       "16965                0                0                          0   \n",
       "16966                0                0                          0   \n",
       "16967                0                0                          0   \n",
       "16968                0                0                          0   \n",
       "\n",
       "       Glucose-type  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 1  \n",
       "...             ...  \n",
       "16964             1  \n",
       "16965             1  \n",
       "16966             1  \n",
       "16967             1  \n",
       "16968             0  \n",
       "\n",
       "[16700 rows x 11 columns]"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "d5e33447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose-type\n",
       "0    7486\n",
       "1    9214\n",
       "dtype: int64"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Glucose-type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "79b2987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Glucose-type', 'Blood Glucose Level(BGL)', 'Diabetic/NonDiabetic (D/N)'], axis=1) \n",
    "y = df['Glucose-type'] \n",
    "##sys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bff33",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "53eb83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "8e4f0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "cb2045ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1] \n",
    "\n",
    "n_classes = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "bbea13ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos de Classe aplicados: {0: 1.1153781933544833, 1: 0.9062542395875729}\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train.to_numpy()\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"Pesos de Classe aplicados: {class_weights_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "b83df113",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "1abb67b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "mlp_keras = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(n_features,)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "68e93f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_126 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_127 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_129 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,457</span> (13.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,457\u001b[0m (13.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,329</span> (13.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,329\u001b[0m (13.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "mlp_keras.compile(\n",
    "    optimizer= optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "mlp_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "5a97d27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Treinando ---\n",
      "Epoch 1/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7551 - loss: 0.5024 - val_accuracy: 0.8231 - val_loss: 0.4355\n",
      "Epoch 2/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8103 - loss: 0.4404 - val_accuracy: 0.8302 - val_loss: 0.4080\n",
      "Epoch 3/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8201 - loss: 0.4271 - val_accuracy: 0.8320 - val_loss: 0.4023\n",
      "Epoch 4/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8194 - loss: 0.4245 - val_accuracy: 0.8326 - val_loss: 0.4008\n",
      "Epoch 5/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8229 - loss: 0.4214 - val_accuracy: 0.8338 - val_loss: 0.4013\n",
      "Epoch 6/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8238 - loss: 0.4168 - val_accuracy: 0.8335 - val_loss: 0.4031\n",
      "Epoch 7/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8243 - loss: 0.4176 - val_accuracy: 0.8335 - val_loss: 0.3981\n",
      "Epoch 8/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8246 - loss: 0.4140 - val_accuracy: 0.8362 - val_loss: 0.3922\n",
      "Epoch 9/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8266 - loss: 0.4140 - val_accuracy: 0.8371 - val_loss: 0.3956\n",
      "Epoch 10/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8264 - loss: 0.4118 - val_accuracy: 0.8356 - val_loss: 0.3915\n",
      "Epoch 11/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8275 - loss: 0.4111 - val_accuracy: 0.8353 - val_loss: 0.3909\n",
      "Epoch 12/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8275 - loss: 0.4112 - val_accuracy: 0.8371 - val_loss: 0.3916\n",
      "Epoch 13/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8287 - loss: 0.4069 - val_accuracy: 0.8374 - val_loss: 0.3905\n",
      "Epoch 14/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8283 - loss: 0.4088 - val_accuracy: 0.8383 - val_loss: 0.3895\n",
      "Epoch 15/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8269 - loss: 0.4077 - val_accuracy: 0.8395 - val_loss: 0.3856\n",
      "Epoch 16/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8278 - loss: 0.4048 - val_accuracy: 0.8392 - val_loss: 0.3884\n",
      "Epoch 17/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8312 - loss: 0.4043 - val_accuracy: 0.8383 - val_loss: 0.3846\n",
      "Epoch 18/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8271 - loss: 0.4040 - val_accuracy: 0.8380 - val_loss: 0.3871\n",
      "Epoch 19/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8303 - loss: 0.4050 - val_accuracy: 0.8392 - val_loss: 0.3883\n",
      "Epoch 20/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8314 - loss: 0.4037 - val_accuracy: 0.8386 - val_loss: 0.3852\n",
      "Epoch 21/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8310 - loss: 0.4018 - val_accuracy: 0.8392 - val_loss: 0.3840\n",
      "Epoch 22/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8338 - loss: 0.4014 - val_accuracy: 0.8386 - val_loss: 0.3841\n",
      "Epoch 23/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8313 - loss: 0.4011 - val_accuracy: 0.8419 - val_loss: 0.3802\n",
      "Epoch 24/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8312 - loss: 0.4008 - val_accuracy: 0.8410 - val_loss: 0.3803\n",
      "Epoch 25/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.3990 - val_accuracy: 0.8380 - val_loss: 0.3861\n",
      "Epoch 26/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.3982 - val_accuracy: 0.8413 - val_loss: 0.3810\n",
      "Epoch 27/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.3970 - val_accuracy: 0.8401 - val_loss: 0.3796\n",
      "Epoch 28/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.4010 - val_accuracy: 0.8398 - val_loss: 0.3811\n",
      "Epoch 29/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 0.3972 - val_accuracy: 0.8407 - val_loss: 0.3780\n",
      "Epoch 30/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.3946 - val_accuracy: 0.8410 - val_loss: 0.3750\n",
      "Epoch 31/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.3955 - val_accuracy: 0.8422 - val_loss: 0.3776\n",
      "Epoch 32/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.3965 - val_accuracy: 0.8428 - val_loss: 0.3813\n",
      "Epoch 33/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.3945 - val_accuracy: 0.8428 - val_loss: 0.3724\n",
      "Epoch 34/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.3919 - val_accuracy: 0.8422 - val_loss: 0.3727\n",
      "Epoch 35/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3941 - val_accuracy: 0.8395 - val_loss: 0.3779\n",
      "Epoch 36/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.3951 - val_accuracy: 0.8422 - val_loss: 0.3771\n",
      "Epoch 37/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.3930 - val_accuracy: 0.8428 - val_loss: 0.3745\n",
      "Epoch 38/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.3916 - val_accuracy: 0.8431 - val_loss: 0.3720\n",
      "Epoch 39/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3918 - val_accuracy: 0.8437 - val_loss: 0.3702\n",
      "Epoch 40/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3921 - val_accuracy: 0.8431 - val_loss: 0.3714\n",
      "Epoch 41/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3906 - val_accuracy: 0.8431 - val_loss: 0.3712\n",
      "Epoch 42/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3919 - val_accuracy: 0.8419 - val_loss: 0.3742\n",
      "Epoch 43/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.3914 - val_accuracy: 0.8410 - val_loss: 0.3711\n",
      "Epoch 44/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.3920 - val_accuracy: 0.8428 - val_loss: 0.3703\n",
      "Epoch 45/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3880 - val_accuracy: 0.8428 - val_loss: 0.3705\n",
      "Epoch 46/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8379 - loss: 0.3887 - val_accuracy: 0.8434 - val_loss: 0.3726\n",
      "Epoch 47/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.3914 - val_accuracy: 0.8428 - val_loss: 0.3735\n",
      "Epoch 48/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.3893 - val_accuracy: 0.8425 - val_loss: 0.3727\n",
      "Epoch 49/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8385 - loss: 0.3886 - val_accuracy: 0.8428 - val_loss: 0.3710\n",
      "Epoch 50/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.3886 - val_accuracy: 0.8425 - val_loss: 0.3705\n",
      "Epoch 51/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3879 - val_accuracy: 0.8437 - val_loss: 0.3716\n",
      "Epoch 52/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.3866 - val_accuracy: 0.8431 - val_loss: 0.3696\n",
      "Epoch 53/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3880 - val_accuracy: 0.8443 - val_loss: 0.3682\n",
      "Epoch 54/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3872 - val_accuracy: 0.8440 - val_loss: 0.3721\n",
      "Epoch 55/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3876 - val_accuracy: 0.8446 - val_loss: 0.3706\n",
      "Epoch 56/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.3895 - val_accuracy: 0.8422 - val_loss: 0.3687\n",
      "Epoch 57/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3863 - val_accuracy: 0.8446 - val_loss: 0.3680\n",
      "Epoch 58/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3867 - val_accuracy: 0.8443 - val_loss: 0.3710\n",
      "Epoch 59/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3868 - val_accuracy: 0.8416 - val_loss: 0.3668\n",
      "Epoch 60/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3862 - val_accuracy: 0.8449 - val_loss: 0.3667\n",
      "Epoch 61/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3871 - val_accuracy: 0.8437 - val_loss: 0.3695\n",
      "Epoch 62/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.3860 - val_accuracy: 0.8440 - val_loss: 0.3663\n",
      "Epoch 63/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3865 - val_accuracy: 0.8428 - val_loss: 0.3694\n",
      "Epoch 64/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.3872 - val_accuracy: 0.8422 - val_loss: 0.3684\n",
      "Epoch 65/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3867 - val_accuracy: 0.8434 - val_loss: 0.3681\n",
      "Epoch 66/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3868 - val_accuracy: 0.8437 - val_loss: 0.3670\n",
      "Epoch 67/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3861 - val_accuracy: 0.8440 - val_loss: 0.3672\n",
      "Epoch 68/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.3872 - val_accuracy: 0.8437 - val_loss: 0.3692\n",
      "Epoch 69/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8379 - loss: 0.3859 - val_accuracy: 0.8431 - val_loss: 0.3686\n",
      "Epoch 70/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3845 - val_accuracy: 0.8434 - val_loss: 0.3658\n",
      "Epoch 71/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8380 - loss: 0.3860 - val_accuracy: 0.8425 - val_loss: 0.3693\n",
      "Epoch 72/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3858 - val_accuracy: 0.8428 - val_loss: 0.3704\n",
      "Epoch 73/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3855 - val_accuracy: 0.8413 - val_loss: 0.3675\n",
      "Epoch 74/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3862 - val_accuracy: 0.8428 - val_loss: 0.3657\n",
      "Epoch 75/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3832 - val_accuracy: 0.8431 - val_loss: 0.3679\n",
      "Epoch 76/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3844 - val_accuracy: 0.8434 - val_loss: 0.3704\n",
      "Epoch 77/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3850 - val_accuracy: 0.8440 - val_loss: 0.3668\n",
      "Epoch 78/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3840 - val_accuracy: 0.8425 - val_loss: 0.3673\n",
      "Epoch 79/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.3851 - val_accuracy: 0.8437 - val_loss: 0.3683\n",
      "Epoch 80/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3848 - val_accuracy: 0.8452 - val_loss: 0.3659\n",
      "Epoch 81/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3843 - val_accuracy: 0.8428 - val_loss: 0.3679\n",
      "Epoch 82/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.3859 - val_accuracy: 0.8419 - val_loss: 0.3691\n",
      "Epoch 83/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3840 - val_accuracy: 0.8434 - val_loss: 0.3699\n",
      "Epoch 84/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3845 - val_accuracy: 0.8434 - val_loss: 0.3683\n",
      "Epoch 85/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3851 - val_accuracy: 0.8446 - val_loss: 0.3666\n",
      "Epoch 86/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.3832 - val_accuracy: 0.8443 - val_loss: 0.3667\n",
      "Epoch 87/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.3843 - val_accuracy: 0.8422 - val_loss: 0.3685\n",
      "Epoch 88/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3848 - val_accuracy: 0.8428 - val_loss: 0.3677\n",
      "Epoch 89/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3843 - val_accuracy: 0.8425 - val_loss: 0.3675\n",
      "Epoch 90/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.3854 - val_accuracy: 0.8434 - val_loss: 0.3663\n",
      "Epoch 91/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8397 - loss: 0.3846 - val_accuracy: 0.8428 - val_loss: 0.3685\n",
      "Epoch 92/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.3832 - val_accuracy: 0.8434 - val_loss: 0.3663\n",
      "Epoch 93/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.3825 - val_accuracy: 0.8443 - val_loss: 0.3644\n",
      "Epoch 94/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3858 - val_accuracy: 0.8440 - val_loss: 0.3667\n",
      "Epoch 95/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3852 - val_accuracy: 0.8440 - val_loss: 0.3634\n",
      "Epoch 96/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3844 - val_accuracy: 0.8443 - val_loss: 0.3654\n",
      "Epoch 97/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3850 - val_accuracy: 0.8434 - val_loss: 0.3659\n",
      "Epoch 98/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3814 - val_accuracy: 0.8443 - val_loss: 0.3663\n",
      "Epoch 99/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3819 - val_accuracy: 0.8437 - val_loss: 0.3657\n",
      "Epoch 100/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3837 - val_accuracy: 0.8437 - val_loss: 0.3668\n",
      "Epoch 101/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3845 - val_accuracy: 0.8437 - val_loss: 0.3672\n",
      "Epoch 102/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3827 - val_accuracy: 0.8440 - val_loss: 0.3652\n",
      "Epoch 103/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3833 - val_accuracy: 0.8437 - val_loss: 0.3645\n",
      "Epoch 104/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3824 - val_accuracy: 0.8431 - val_loss: 0.3646\n",
      "Epoch 105/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3812 - val_accuracy: 0.8437 - val_loss: 0.3654\n",
      "Epoch 106/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3837 - val_accuracy: 0.8440 - val_loss: 0.3649\n",
      "Epoch 107/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3829 - val_accuracy: 0.8431 - val_loss: 0.3641\n",
      "Epoch 108/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3806 - val_accuracy: 0.8422 - val_loss: 0.3658\n",
      "Epoch 109/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3818 - val_accuracy: 0.8425 - val_loss: 0.3656\n",
      "Epoch 110/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3813 - val_accuracy: 0.8452 - val_loss: 0.3639\n",
      "Epoch 111/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3847 - val_accuracy: 0.8440 - val_loss: 0.3632\n",
      "Epoch 112/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3809 - val_accuracy: 0.8422 - val_loss: 0.3645\n",
      "Epoch 113/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3811 - val_accuracy: 0.8419 - val_loss: 0.3635\n",
      "Epoch 114/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3827 - val_accuracy: 0.8425 - val_loss: 0.3669\n",
      "Epoch 115/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8374 - loss: 0.3827 - val_accuracy: 0.8443 - val_loss: 0.3632\n",
      "Epoch 116/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3814 - val_accuracy: 0.8446 - val_loss: 0.3644\n",
      "Epoch 117/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3815 - val_accuracy: 0.8443 - val_loss: 0.3643\n",
      "Epoch 118/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3811 - val_accuracy: 0.8440 - val_loss: 0.3669\n",
      "Epoch 119/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3816 - val_accuracy: 0.8440 - val_loss: 0.3687\n",
      "Epoch 120/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.3811 - val_accuracy: 0.8449 - val_loss: 0.3656\n",
      "Epoch 121/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8386 - loss: 0.3824 - val_accuracy: 0.8425 - val_loss: 0.3649\n",
      "Epoch 122/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.3801 - val_accuracy: 0.8458 - val_loss: 0.3667\n",
      "Epoch 123/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3823 - val_accuracy: 0.8434 - val_loss: 0.3659\n",
      "Epoch 124/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3809 - val_accuracy: 0.8449 - val_loss: 0.3651\n",
      "Epoch 125/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8423 - loss: 0.3796 - val_accuracy: 0.8443 - val_loss: 0.3655\n",
      "Epoch 126/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.3805 - val_accuracy: 0.8437 - val_loss: 0.3626\n",
      "Epoch 127/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3801 - val_accuracy: 0.8425 - val_loss: 0.3622\n",
      "Epoch 128/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.3815 - val_accuracy: 0.8440 - val_loss: 0.3632\n",
      "Epoch 129/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3791 - val_accuracy: 0.8431 - val_loss: 0.3636\n",
      "Epoch 130/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3805 - val_accuracy: 0.8443 - val_loss: 0.3633\n",
      "Epoch 131/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3796 - val_accuracy: 0.8431 - val_loss: 0.3629\n",
      "Epoch 132/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3792 - val_accuracy: 0.8419 - val_loss: 0.3633\n",
      "Epoch 133/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3795 - val_accuracy: 0.8446 - val_loss: 0.3617\n",
      "Epoch 134/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3787 - val_accuracy: 0.8431 - val_loss: 0.3635\n",
      "Epoch 135/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.3787 - val_accuracy: 0.8440 - val_loss: 0.3596\n",
      "Epoch 136/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8397 - loss: 0.3803 - val_accuracy: 0.8437 - val_loss: 0.3628\n",
      "Epoch 137/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3809 - val_accuracy: 0.8434 - val_loss: 0.3605\n",
      "Epoch 138/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3797 - val_accuracy: 0.8446 - val_loss: 0.3640\n",
      "Epoch 139/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.3802 - val_accuracy: 0.8452 - val_loss: 0.3635\n",
      "Epoch 140/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.3808 - val_accuracy: 0.8434 - val_loss: 0.3642\n",
      "Epoch 141/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3784 - val_accuracy: 0.8422 - val_loss: 0.3640\n",
      "Epoch 142/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3790 - val_accuracy: 0.8449 - val_loss: 0.3627\n",
      "Epoch 143/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.3800 - val_accuracy: 0.8446 - val_loss: 0.3620\n",
      "Epoch 144/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3792 - val_accuracy: 0.8452 - val_loss: 0.3611\n",
      "Epoch 145/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.3792 - val_accuracy: 0.8443 - val_loss: 0.3616\n",
      "Epoch 146/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.3805 - val_accuracy: 0.8452 - val_loss: 0.3650\n",
      "Epoch 147/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3823 - val_accuracy: 0.8428 - val_loss: 0.3625\n",
      "Epoch 148/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.3789 - val_accuracy: 0.8434 - val_loss: 0.3644\n",
      "Epoch 149/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3776 - val_accuracy: 0.8446 - val_loss: 0.3621\n",
      "Epoch 150/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8387 - loss: 0.3810 - val_accuracy: 0.8419 - val_loss: 0.3661\n",
      "Epoch 151/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3771 - val_accuracy: 0.8437 - val_loss: 0.3622\n",
      "Epoch 152/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3802 - val_accuracy: 0.8443 - val_loss: 0.3637\n",
      "Epoch 153/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3784 - val_accuracy: 0.8443 - val_loss: 0.3617\n",
      "Epoch 154/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.3781 - val_accuracy: 0.8437 - val_loss: 0.3604\n",
      "Epoch 155/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.3800 - val_accuracy: 0.8464 - val_loss: 0.3629\n",
      "Epoch 156/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8381 - loss: 0.3796 - val_accuracy: 0.8464 - val_loss: 0.3625\n",
      "Epoch 157/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3802 - val_accuracy: 0.8461 - val_loss: 0.3634\n",
      "Epoch 158/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3798 - val_accuracy: 0.8452 - val_loss: 0.3622\n",
      "Epoch 159/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3785 - val_accuracy: 0.8452 - val_loss: 0.3601\n",
      "Epoch 160/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3774 - val_accuracy: 0.8452 - val_loss: 0.3635\n",
      "Epoch 161/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3800 - val_accuracy: 0.8473 - val_loss: 0.3627\n",
      "Epoch 162/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8381 - loss: 0.3787 - val_accuracy: 0.8458 - val_loss: 0.3606\n",
      "Epoch 163/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3791 - val_accuracy: 0.8440 - val_loss: 0.3605\n",
      "Epoch 164/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3795 - val_accuracy: 0.8461 - val_loss: 0.3609\n",
      "Epoch 165/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.3765 - val_accuracy: 0.8473 - val_loss: 0.3615\n",
      "Epoch 166/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.3772 - val_accuracy: 0.8443 - val_loss: 0.3607\n",
      "Epoch 167/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.3764 - val_accuracy: 0.8455 - val_loss: 0.3624\n",
      "Epoch 168/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.3768 - val_accuracy: 0.8464 - val_loss: 0.3614\n",
      "Epoch 169/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3801 - val_accuracy: 0.8443 - val_loss: 0.3625\n",
      "Epoch 170/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3790 - val_accuracy: 0.8437 - val_loss: 0.3629\n",
      "Epoch 171/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3791 - val_accuracy: 0.8458 - val_loss: 0.3621\n",
      "Epoch 172/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3801 - val_accuracy: 0.8458 - val_loss: 0.3595\n",
      "Epoch 173/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.3769 - val_accuracy: 0.8452 - val_loss: 0.3623\n",
      "Epoch 174/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3774 - val_accuracy: 0.8452 - val_loss: 0.3623\n",
      "Epoch 175/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.3769 - val_accuracy: 0.8434 - val_loss: 0.3634\n",
      "Epoch 176/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.3790 - val_accuracy: 0.8461 - val_loss: 0.3613\n",
      "Epoch 177/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3785 - val_accuracy: 0.8458 - val_loss: 0.3612\n",
      "Epoch 178/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.3785 - val_accuracy: 0.8455 - val_loss: 0.3609\n",
      "Epoch 179/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.3779 - val_accuracy: 0.8446 - val_loss: 0.3635\n",
      "Epoch 180/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3769 - val_accuracy: 0.8458 - val_loss: 0.3607\n",
      "Epoch 181/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.3764 - val_accuracy: 0.8470 - val_loss: 0.3636\n",
      "Epoch 182/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.3781 - val_accuracy: 0.8452 - val_loss: 0.3618\n",
      "Epoch 183/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3767 - val_accuracy: 0.8437 - val_loss: 0.3633\n",
      "Epoch 184/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3764 - val_accuracy: 0.8404 - val_loss: 0.3626\n",
      "Epoch 185/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.3790 - val_accuracy: 0.8470 - val_loss: 0.3605\n",
      "Epoch 186/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.3779 - val_accuracy: 0.8440 - val_loss: 0.3614\n",
      "Epoch 187/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.3788 - val_accuracy: 0.8473 - val_loss: 0.3601\n",
      "Epoch 188/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3765 - val_accuracy: 0.8452 - val_loss: 0.3649\n",
      "Epoch 189/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3797 - val_accuracy: 0.8455 - val_loss: 0.3619\n",
      "Epoch 190/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3789 - val_accuracy: 0.8455 - val_loss: 0.3617\n",
      "Epoch 191/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.3779 - val_accuracy: 0.8470 - val_loss: 0.3632\n",
      "Epoch 192/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3753 - val_accuracy: 0.8443 - val_loss: 0.3631\n",
      "Epoch 193/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3782 - val_accuracy: 0.8467 - val_loss: 0.3599\n",
      "Epoch 194/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.3758 - val_accuracy: 0.8413 - val_loss: 0.3616\n",
      "Epoch 195/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3774 - val_accuracy: 0.8434 - val_loss: 0.3625\n",
      "Epoch 196/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3775 - val_accuracy: 0.8428 - val_loss: 0.3633\n",
      "Epoch 197/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3768 - val_accuracy: 0.8455 - val_loss: 0.3613\n",
      "Epoch 198/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3768 - val_accuracy: 0.8431 - val_loss: 0.3609\n",
      "Epoch 199/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3775 - val_accuracy: 0.8431 - val_loss: 0.3615\n",
      "Epoch 200/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.3767 - val_accuracy: 0.8431 - val_loss: 0.3608\n",
      "Epoch 201/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.3780 - val_accuracy: 0.8440 - val_loss: 0.3623\n",
      "Epoch 202/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3779 - val_accuracy: 0.8449 - val_loss: 0.3603\n",
      "Epoch 203/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3754 - val_accuracy: 0.8452 - val_loss: 0.3610\n",
      "Epoch 204/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3742 - val_accuracy: 0.8455 - val_loss: 0.3617\n",
      "Epoch 205/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.3762 - val_accuracy: 0.8452 - val_loss: 0.3599\n",
      "Epoch 206/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3746 - val_accuracy: 0.8461 - val_loss: 0.3593\n",
      "Epoch 207/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.3763 - val_accuracy: 0.8443 - val_loss: 0.3620\n",
      "Epoch 208/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3767 - val_accuracy: 0.8419 - val_loss: 0.3622\n",
      "Epoch 209/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.3774 - val_accuracy: 0.8446 - val_loss: 0.3590\n",
      "Epoch 210/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3766 - val_accuracy: 0.8470 - val_loss: 0.3589\n",
      "Epoch 211/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.3769 - val_accuracy: 0.8455 - val_loss: 0.3587\n",
      "Epoch 212/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.3767 - val_accuracy: 0.8446 - val_loss: 0.3597\n",
      "Epoch 213/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3752 - val_accuracy: 0.8455 - val_loss: 0.3603\n",
      "Epoch 214/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.3776 - val_accuracy: 0.8443 - val_loss: 0.3616\n",
      "Epoch 215/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.3741 - val_accuracy: 0.8449 - val_loss: 0.3643\n",
      "Epoch 216/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3776 - val_accuracy: 0.8458 - val_loss: 0.3603\n",
      "Epoch 217/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.3759 - val_accuracy: 0.8461 - val_loss: 0.3635\n",
      "Epoch 218/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.3747 - val_accuracy: 0.8446 - val_loss: 0.3619\n",
      "Epoch 219/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3763 - val_accuracy: 0.8452 - val_loss: 0.3609\n",
      "Epoch 220/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3778 - val_accuracy: 0.8443 - val_loss: 0.3615\n",
      "Epoch 221/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.3772 - val_accuracy: 0.8434 - val_loss: 0.3614\n",
      "Epoch 222/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8426 - loss: 0.3741 - val_accuracy: 0.8449 - val_loss: 0.3606\n",
      "Epoch 223/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8403 - loss: 0.3751 - val_accuracy: 0.8437 - val_loss: 0.3606\n",
      "Epoch 224/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3758 - val_accuracy: 0.8452 - val_loss: 0.3603\n",
      "Epoch 225/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8379 - loss: 0.3755 - val_accuracy: 0.8449 - val_loss: 0.3615\n",
      "Epoch 226/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.3763 - val_accuracy: 0.8449 - val_loss: 0.3632\n",
      "Epoch 227/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.3774 - val_accuracy: 0.8416 - val_loss: 0.3619\n",
      "Epoch 228/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3732 - val_accuracy: 0.8431 - val_loss: 0.3598\n",
      "Epoch 229/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.3743 - val_accuracy: 0.8404 - val_loss: 0.3602\n",
      "Epoch 230/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8414 - loss: 0.3743 - val_accuracy: 0.8437 - val_loss: 0.3608\n",
      "Epoch 231/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.3763 - val_accuracy: 0.8413 - val_loss: 0.3630\n",
      "Epoch 232/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8415 - loss: 0.3748 - val_accuracy: 0.8467 - val_loss: 0.3592\n",
      "Epoch 233/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3751 - val_accuracy: 0.8452 - val_loss: 0.3599\n",
      "Epoch 234/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.3738 - val_accuracy: 0.8452 - val_loss: 0.3595\n",
      "Epoch 235/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.3750 - val_accuracy: 0.8431 - val_loss: 0.3618\n",
      "Epoch 236/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.3759 - val_accuracy: 0.8443 - val_loss: 0.3598\n",
      "Epoch 237/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.3738 - val_accuracy: 0.8458 - val_loss: 0.3602\n",
      "Epoch 238/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3729 - val_accuracy: 0.8458 - val_loss: 0.3593\n",
      "Epoch 239/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8403 - loss: 0.3764 - val_accuracy: 0.8461 - val_loss: 0.3604\n",
      "Epoch 240/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.3730 - val_accuracy: 0.8437 - val_loss: 0.3654\n",
      "Epoch 241/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.3747 - val_accuracy: 0.8446 - val_loss: 0.3612\n",
      "Epoch 242/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8429 - loss: 0.3737 - val_accuracy: 0.8458 - val_loss: 0.3618\n",
      "Epoch 243/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3734 - val_accuracy: 0.8422 - val_loss: 0.3609\n",
      "Epoch 244/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3751 - val_accuracy: 0.8434 - val_loss: 0.3628\n",
      "Epoch 245/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.3747 - val_accuracy: 0.8422 - val_loss: 0.3613\n",
      "Epoch 246/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3742 - val_accuracy: 0.8446 - val_loss: 0.3602\n",
      "Epoch 247/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3745 - val_accuracy: 0.8455 - val_loss: 0.3591\n",
      "Epoch 248/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.3745 - val_accuracy: 0.8449 - val_loss: 0.3596\n",
      "Epoch 249/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.3724 - val_accuracy: 0.8422 - val_loss: 0.3614\n",
      "Epoch 250/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.3758 - val_accuracy: 0.8443 - val_loss: 0.3586\n",
      "Epoch 251/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.3755 - val_accuracy: 0.8440 - val_loss: 0.3652\n",
      "Epoch 252/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.3767 - val_accuracy: 0.8437 - val_loss: 0.3603\n",
      "Epoch 253/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.3742 - val_accuracy: 0.8428 - val_loss: 0.3607\n",
      "Epoch 254/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3745 - val_accuracy: 0.8446 - val_loss: 0.3577\n",
      "Epoch 255/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8429 - loss: 0.3736 - val_accuracy: 0.8437 - val_loss: 0.3612\n",
      "Epoch 256/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8426 - loss: 0.3736 - val_accuracy: 0.8440 - val_loss: 0.3595\n",
      "Epoch 257/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8424 - loss: 0.3745 - val_accuracy: 0.8422 - val_loss: 0.3606\n",
      "Epoch 258/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.3728 - val_accuracy: 0.8431 - val_loss: 0.3593\n",
      "Epoch 259/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.3735 - val_accuracy: 0.8431 - val_loss: 0.3585\n",
      "Epoch 260/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3733 - val_accuracy: 0.8434 - val_loss: 0.3610\n",
      "Epoch 261/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3733 - val_accuracy: 0.8437 - val_loss: 0.3596\n",
      "Epoch 262/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.3745 - val_accuracy: 0.8464 - val_loss: 0.3593\n",
      "Epoch 263/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.3747 - val_accuracy: 0.8413 - val_loss: 0.3605\n",
      "Epoch 264/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.3756 - val_accuracy: 0.8461 - val_loss: 0.3635\n",
      "Epoch 265/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.3738 - val_accuracy: 0.8431 - val_loss: 0.3607\n",
      "Epoch 266/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3732 - val_accuracy: 0.8440 - val_loss: 0.3590\n",
      "Epoch 267/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.3747 - val_accuracy: 0.8461 - val_loss: 0.3618\n",
      "Epoch 268/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8401 - loss: 0.3743 - val_accuracy: 0.8437 - val_loss: 0.3596\n",
      "Epoch 269/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3741 - val_accuracy: 0.8455 - val_loss: 0.3604\n",
      "Epoch 270/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3760 - val_accuracy: 0.8431 - val_loss: 0.3617\n",
      "Epoch 271/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3750 - val_accuracy: 0.8437 - val_loss: 0.3627\n",
      "Epoch 272/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3734 - val_accuracy: 0.8452 - val_loss: 0.3608\n",
      "Epoch 273/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8415 - loss: 0.3742 - val_accuracy: 0.8434 - val_loss: 0.3582\n",
      "Epoch 274/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.3752 - val_accuracy: 0.8443 - val_loss: 0.3627\n",
      "Epoch 275/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3733 - val_accuracy: 0.8449 - val_loss: 0.3607\n",
      "Epoch 276/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.3733 - val_accuracy: 0.8446 - val_loss: 0.3606\n",
      "Epoch 277/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3745 - val_accuracy: 0.8431 - val_loss: 0.3602\n",
      "Epoch 278/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.3736 - val_accuracy: 0.8446 - val_loss: 0.3595\n",
      "Epoch 279/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.3750 - val_accuracy: 0.8431 - val_loss: 0.3607\n",
      "Epoch 280/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: 0.3742 - val_accuracy: 0.8440 - val_loss: 0.3602\n",
      "Epoch 281/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.3739 - val_accuracy: 0.8437 - val_loss: 0.3601\n",
      "Epoch 282/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.3734 - val_accuracy: 0.8446 - val_loss: 0.3596\n",
      "Epoch 283/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3726 - val_accuracy: 0.8419 - val_loss: 0.3611\n",
      "Epoch 284/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.3718 - val_accuracy: 0.8437 - val_loss: 0.3606\n",
      "Epoch 285/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.3742 - val_accuracy: 0.8431 - val_loss: 0.3592\n",
      "Epoch 286/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.3722 - val_accuracy: 0.8455 - val_loss: 0.3589\n",
      "Epoch 287/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8416 - loss: 0.3755 - val_accuracy: 0.8461 - val_loss: 0.3604\n",
      "Epoch 288/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.3728 - val_accuracy: 0.8440 - val_loss: 0.3583\n",
      "Epoch 289/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3749 - val_accuracy: 0.8428 - val_loss: 0.3590\n",
      "Epoch 290/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3727 - val_accuracy: 0.8437 - val_loss: 0.3653\n",
      "Epoch 291/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.3730 - val_accuracy: 0.8437 - val_loss: 0.3619\n",
      "Epoch 292/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.3725 - val_accuracy: 0.8431 - val_loss: 0.3602\n",
      "Epoch 293/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.3720 - val_accuracy: 0.8449 - val_loss: 0.3615\n",
      "Epoch 294/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3731 - val_accuracy: 0.8452 - val_loss: 0.3602\n",
      "Treinamento concluído!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Treinando ---\")\n",
    "history = mlp_keras.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    class_weight=class_weights_dict,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    "    \n",
    ")\n",
    "print(\"Treinamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "1c6c1880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Avaliando o modelo no conjunto de teste ---\n",
      "Acurácia no conjunto de teste: 0.8446\n",
      "Loss no conjunto de teste: 0.3577\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Avaliando o modelo no conjunto de teste ---\")\n",
    "test_loss, test_accuracy = mlp_keras.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Acurácia no conjunto de teste: {test_accuracy:.4f}\")\n",
    "print(f\"Loss no conjunto de teste: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "e1915508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Melhor limiar: 0.4349221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1a17637d5b0>"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_scores = mlp_keras.predict(X_test).ravel()\n",
    "\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "f1 = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
    "best_threshold = thresholds[np.argmax(f1)]\n",
    "\n",
    "print(\"Melhor limiar:\", best_threshold)\n",
    "\n",
    "y_pred = (y_scores > best_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
