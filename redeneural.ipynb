{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3782b837",
   "metadata": {},
   "source": [
    "## Iniciando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4802061",
   "metadata": {},
   "source": [
    "## Definindo o database, realizando limpeza de dados e definindo classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "febd7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('db.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Glucose-type'] = 0\n",
    "df.loc[(df['Blood Glucose Level(BGL)'] > 80), 'Glucose-type'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "57490e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Diabetic/NonDiabetic (D/N)'] == 'N', 'Diabetic/NonDiabetic (D/N)'] = 1\n",
    "df.loc[df['Diabetic/NonDiabetic (D/N)'] == 'D', 'Diabetic/NonDiabetic (D/N)'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "4a1451f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Blood Glucose Level(BGL)</th>\n",
       "      <th>Diastolic Blood Pressure</th>\n",
       "      <th>Systolic Blood Pressure</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Body Temperature</th>\n",
       "      <th>SPO2</th>\n",
       "      <th>Sweating  (Y/N)</th>\n",
       "      <th>Shivering (Y/N)</th>\n",
       "      <th>Diabetic/NonDiabetic (D/N)</th>\n",
       "      <th>Glucose-type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>73</td>\n",
       "      <td>118</td>\n",
       "      <td>98</td>\n",
       "      <td>98.300707</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>119</td>\n",
       "      <td>102</td>\n",
       "      <td>98.300707</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>110</td>\n",
       "      <td>81</td>\n",
       "      <td>98.300707</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>115</td>\n",
       "      <td>96</td>\n",
       "      <td>98.300707</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>144</td>\n",
       "      <td>92</td>\n",
       "      <td>97.807052</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>127</td>\n",
       "      <td>90</td>\n",
       "      <td>96.842657</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16965</th>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>117</td>\n",
       "      <td>80</td>\n",
       "      <td>97.869454</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16966</th>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>116</td>\n",
       "      <td>93</td>\n",
       "      <td>96.766282</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16967</th>\n",
       "      <td>9</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>128</td>\n",
       "      <td>91</td>\n",
       "      <td>98.941036</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16968</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "      <td>117</td>\n",
       "      <td>79</td>\n",
       "      <td>97.570685</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16700 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Blood Glucose Level(BGL)  Diastolic Blood Pressure  \\\n",
       "0        9                        79                        73   \n",
       "1        9                        80                        73   \n",
       "2        9                        70                        76   \n",
       "3        9                        70                        78   \n",
       "4       66                       100                        96   \n",
       "...    ...                       ...                       ...   \n",
       "16964    9                        86                        87   \n",
       "16965    9                        84                        79   \n",
       "16966    9                        81                        82   \n",
       "16967    9                        82                        86   \n",
       "16968    9                        76                        85   \n",
       "\n",
       "       Systolic Blood Pressure  Heart Rate  Body Temperature  SPO2  \\\n",
       "0                          118          98         98.300707    99   \n",
       "1                          119         102         98.300707    94   \n",
       "2                          110          81         98.300707    98   \n",
       "3                          115          96         98.300707    96   \n",
       "4                          144          92         97.807052    98   \n",
       "...                        ...         ...               ...   ...   \n",
       "16964                      127          90         96.842657    97   \n",
       "16965                      117          80         97.869454    98   \n",
       "16966                      116          93         96.766282    98   \n",
       "16967                      128          91         98.941036    98   \n",
       "16968                      117          79         97.570685    97   \n",
       "\n",
       "       Sweating  (Y/N)  Shivering (Y/N) Diabetic/NonDiabetic (D/N)  \\\n",
       "0                    0                0                          1   \n",
       "1                    1                0                          1   \n",
       "2                    1                0                          1   \n",
       "3                    1                0                          1   \n",
       "4                    0                0                          1   \n",
       "...                ...              ...                        ...   \n",
       "16964                0                0                          0   \n",
       "16965                0                0                          0   \n",
       "16966                0                0                          0   \n",
       "16967                0                0                          0   \n",
       "16968                0                0                          0   \n",
       "\n",
       "       Glucose-type  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "16964             0  \n",
       "16965             0  \n",
       "16966             0  \n",
       "16967             0  \n",
       "16968             0  \n",
       "\n",
       "[16700 rows x 11 columns]"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "d5e33447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose-type\n",
       "0    11396\n",
       "1     5304\n",
       "dtype: int64"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Glucose-type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "79b2987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Glucose-type', 'Blood Glucose Level(BGL)', 'Diabetic/NonDiabetic (D/N)'], axis=1) \n",
    "y = df['Glucose-type'] \n",
    "##sys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bff33",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "53eb83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "8e4f0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "cb2045ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1] \n",
    "\n",
    "n_classes = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "bbea13ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos de Classe aplicados: {0: 0.7326971591532302, 1: 1.5743577657317935}\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train.to_numpy()\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"Pesos de Classe aplicados: {class_weights_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "b83df113",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "1abb67b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "mlp_keras = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(n_features,)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "68e93f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_122 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_125 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,457</span> (13.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,457\u001b[0m (13.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,329</span> (13.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,329\u001b[0m (13.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "mlp_keras.compile(\n",
    "    optimizer= optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "mlp_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "5a97d27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Treinando ---\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6157 - loss: 0.5825 - val_accuracy: 0.6102 - val_loss: 0.5528\n",
      "Epoch 2/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.5415 - val_accuracy: 0.6135 - val_loss: 0.5401\n",
      "Epoch 3/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6190 - loss: 0.5375 - val_accuracy: 0.6111 - val_loss: 0.5410\n",
      "Epoch 4/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6163 - loss: 0.5345 - val_accuracy: 0.6078 - val_loss: 0.5408\n",
      "Epoch 5/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.5326 - val_accuracy: 0.6135 - val_loss: 0.5338\n",
      "Epoch 6/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6168 - loss: 0.5279 - val_accuracy: 0.6123 - val_loss: 0.5285\n",
      "Epoch 7/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.5281 - val_accuracy: 0.6081 - val_loss: 0.5388\n",
      "Epoch 8/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.5263 - val_accuracy: 0.6114 - val_loss: 0.5402\n",
      "Epoch 9/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6193 - loss: 0.5251 - val_accuracy: 0.6105 - val_loss: 0.5361\n",
      "Epoch 10/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.5245 - val_accuracy: 0.6126 - val_loss: 0.5377\n",
      "Epoch 11/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6159 - loss: 0.5234 - val_accuracy: 0.6135 - val_loss: 0.5304\n",
      "Epoch 12/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6209 - loss: 0.5206 - val_accuracy: 0.6126 - val_loss: 0.5376\n",
      "Epoch 13/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6174 - loss: 0.5225 - val_accuracy: 0.6129 - val_loss: 0.5300\n",
      "Epoch 14/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.5218 - val_accuracy: 0.6102 - val_loss: 0.5402\n",
      "Epoch 15/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6165 - loss: 0.5223 - val_accuracy: 0.6120 - val_loss: 0.5356\n",
      "Epoch 16/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.5220 - val_accuracy: 0.6108 - val_loss: 0.5356\n",
      "Epoch 17/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6198 - loss: 0.5199 - val_accuracy: 0.6183 - val_loss: 0.5281\n",
      "Epoch 18/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6195 - loss: 0.5200 - val_accuracy: 0.6123 - val_loss: 0.5337\n",
      "Epoch 19/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6216 - loss: 0.5177 - val_accuracy: 0.6159 - val_loss: 0.5386\n",
      "Epoch 20/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6186 - loss: 0.5174 - val_accuracy: 0.6135 - val_loss: 0.5360\n",
      "Epoch 21/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 0.5172 - val_accuracy: 0.6138 - val_loss: 0.5322\n",
      "Epoch 22/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.5189 - val_accuracy: 0.6111 - val_loss: 0.5362\n",
      "Epoch 23/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6198 - loss: 0.5152 - val_accuracy: 0.6120 - val_loss: 0.5357\n",
      "Epoch 24/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6214 - loss: 0.5189 - val_accuracy: 0.6135 - val_loss: 0.5415\n",
      "Epoch 25/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 0.5153 - val_accuracy: 0.6135 - val_loss: 0.5345\n",
      "Epoch 26/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6228 - loss: 0.5150 - val_accuracy: 0.6138 - val_loss: 0.5379\n",
      "Epoch 27/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 0.5160 - val_accuracy: 0.6147 - val_loss: 0.5377\n",
      "Epoch 28/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6224 - loss: 0.5147 - val_accuracy: 0.6162 - val_loss: 0.5334\n",
      "Epoch 29/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6212 - loss: 0.5165 - val_accuracy: 0.6120 - val_loss: 0.5368\n",
      "Epoch 30/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6241 - loss: 0.5140 - val_accuracy: 0.6135 - val_loss: 0.5418\n",
      "Epoch 31/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6233 - loss: 0.5132 - val_accuracy: 0.6159 - val_loss: 0.5331\n",
      "Epoch 32/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 0.5147 - val_accuracy: 0.6132 - val_loss: 0.5312\n",
      "Epoch 33/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6235 - loss: 0.5131 - val_accuracy: 0.6156 - val_loss: 0.5345\n",
      "Epoch 34/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6228 - loss: 0.5135 - val_accuracy: 0.6135 - val_loss: 0.5296\n",
      "Epoch 35/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.5138 - val_accuracy: 0.6159 - val_loss: 0.5341\n",
      "Epoch 36/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6196 - loss: 0.5129 - val_accuracy: 0.6171 - val_loss: 0.5359\n",
      "Epoch 37/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.5138 - val_accuracy: 0.6141 - val_loss: 0.5365\n",
      "Epoch 38/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6263 - loss: 0.5112 - val_accuracy: 0.6174 - val_loss: 0.5344\n",
      "Epoch 39/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6253 - loss: 0.5110 - val_accuracy: 0.6213 - val_loss: 0.5210\n",
      "Epoch 40/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6233 - loss: 0.5135 - val_accuracy: 0.6150 - val_loss: 0.5321\n",
      "Epoch 41/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6259 - loss: 0.5104 - val_accuracy: 0.6168 - val_loss: 0.5324\n",
      "Epoch 42/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6241 - loss: 0.5115 - val_accuracy: 0.6177 - val_loss: 0.5344\n",
      "Epoch 43/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6251 - loss: 0.5104 - val_accuracy: 0.6114 - val_loss: 0.5437\n",
      "Epoch 44/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.5110 - val_accuracy: 0.6156 - val_loss: 0.5347\n",
      "Epoch 45/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 0.5108 - val_accuracy: 0.6117 - val_loss: 0.5352\n",
      "Epoch 46/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6231 - loss: 0.5118 - val_accuracy: 0.6162 - val_loss: 0.5368\n",
      "Epoch 47/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6216 - loss: 0.5120 - val_accuracy: 0.6162 - val_loss: 0.5339\n",
      "Epoch 48/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6275 - loss: 0.5107 - val_accuracy: 0.6183 - val_loss: 0.5324\n",
      "Epoch 49/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6293 - loss: 0.5089 - val_accuracy: 0.6138 - val_loss: 0.5347\n",
      "Epoch 50/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.5082 - val_accuracy: 0.6153 - val_loss: 0.5302\n",
      "Epoch 51/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6271 - loss: 0.5092 - val_accuracy: 0.6171 - val_loss: 0.5330\n",
      "Epoch 52/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.5095 - val_accuracy: 0.6180 - val_loss: 0.5359\n",
      "Epoch 53/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6247 - loss: 0.5110 - val_accuracy: 0.6189 - val_loss: 0.5346\n",
      "Epoch 54/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: 0.5070 - val_accuracy: 0.6141 - val_loss: 0.5430\n",
      "Epoch 55/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6292 - loss: 0.5082 - val_accuracy: 0.6156 - val_loss: 0.5356\n",
      "Epoch 56/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6302 - loss: 0.5089 - val_accuracy: 0.6228 - val_loss: 0.5312\n",
      "Epoch 57/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6369 - loss: 0.5065 - val_accuracy: 0.6195 - val_loss: 0.5352\n",
      "Epoch 58/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6307 - loss: 0.5081 - val_accuracy: 0.6174 - val_loss: 0.5349\n",
      "Epoch 59/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6305 - loss: 0.5090 - val_accuracy: 0.6180 - val_loss: 0.5310\n",
      "Epoch 60/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6320 - loss: 0.5090 - val_accuracy: 0.6156 - val_loss: 0.5354\n",
      "Epoch 61/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: 0.5062 - val_accuracy: 0.6222 - val_loss: 0.5312\n",
      "Epoch 62/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.5073 - val_accuracy: 0.6162 - val_loss: 0.5394\n",
      "Epoch 63/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6303 - loss: 0.5068 - val_accuracy: 0.6180 - val_loss: 0.5334\n",
      "Epoch 64/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6326 - loss: 0.5057 - val_accuracy: 0.6189 - val_loss: 0.5418\n",
      "Epoch 65/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6359 - loss: 0.5078 - val_accuracy: 0.6198 - val_loss: 0.5358\n",
      "Epoch 66/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6335 - loss: 0.5079 - val_accuracy: 0.6222 - val_loss: 0.5311\n",
      "Epoch 67/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6356 - loss: 0.5064 - val_accuracy: 0.6132 - val_loss: 0.5333\n",
      "Epoch 68/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6299 - loss: 0.5070 - val_accuracy: 0.6174 - val_loss: 0.5329\n",
      "Epoch 69/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6310 - loss: 0.5075 - val_accuracy: 0.6237 - val_loss: 0.5299\n",
      "Epoch 70/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6305 - loss: 0.5061 - val_accuracy: 0.6269 - val_loss: 0.5334\n",
      "Epoch 71/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6373 - loss: 0.5041 - val_accuracy: 0.6246 - val_loss: 0.5280\n",
      "Epoch 72/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6362 - loss: 0.5055 - val_accuracy: 0.6195 - val_loss: 0.5362\n",
      "Epoch 73/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6326 - loss: 0.5058 - val_accuracy: 0.6284 - val_loss: 0.5343\n",
      "Epoch 74/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6353 - loss: 0.5083 - val_accuracy: 0.6186 - val_loss: 0.5383\n",
      "Epoch 75/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: 0.5042 - val_accuracy: 0.6213 - val_loss: 0.5387\n",
      "Epoch 76/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.5069 - val_accuracy: 0.6269 - val_loss: 0.5272\n",
      "Epoch 77/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6331 - loss: 0.5049 - val_accuracy: 0.6272 - val_loss: 0.5317\n",
      "Epoch 78/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6326 - loss: 0.5058 - val_accuracy: 0.6237 - val_loss: 0.5353\n",
      "Epoch 79/500\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6352 - loss: 0.5051 - val_accuracy: 0.6260 - val_loss: 0.5314\n",
      "Treinamento concluído!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Treinando ---\")\n",
    "history = mlp_keras.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    class_weight=class_weights_dict,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    "    \n",
    ")\n",
    "print(\"Treinamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "1c6c1880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Avaliando o modelo no conjunto de teste ---\n",
      "Acurácia no conjunto de teste: 0.6213\n",
      "Loss no conjunto de teste: 0.5210\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Avaliando o modelo no conjunto de teste ---\")\n",
    "test_loss, test_accuracy = mlp_keras.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Acurácia no conjunto de teste: {test_accuracy:.4f}\")\n",
    "print(f\"Loss no conjunto de teste: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "e1915508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Melhor limiar: 0.55007595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1a102aa12e0>"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_scores = mlp_keras.predict(X_test).ravel()\n",
    "\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "f1 = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
    "best_threshold = thresholds[np.argmax(f1)]\n",
    "\n",
    "print(\"Melhor limiar:\", best_threshold)\n",
    "\n",
    "y_pred = (y_scores > best_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
